{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (23,39,47,48,49,50,54,55,57,70,71,72,73,83,88,92,93,94,102,103) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (15,21,23,31,37,39,47,48,49,50,54,55,57,59,65,66,70,71,72,73,75,83,88,92,93,94,102,103) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Activation, Dense, Dropout, SpatialDropout1D,Input,Masking,Bidirectional, TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import seed\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#seed(1)\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import scipy.stats\n",
    "from prettytable import PrettyTable\n",
    "import math\n",
    "import itertools\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "#defining the early stopping criteria\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,restore_best_weights=True,patience=3)\n",
    "\n",
    "gs = pd.read_csv('lstm_analysis.csv')\n",
    "gs['urine_per_kg_hour'] = gs['urine_per_hour']/gs['currentdateweight']\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gs.drop('Unnamed: 0.1',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def split_70(x):\n",
    "    return int((round((x/15)*0.7))*15)\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return round(m,3), round(m-h,3), round(m+h,3)\n",
    "\n",
    "\n",
    "\n",
    "def range_finder(x):\n",
    "    length = x\n",
    "    fractional = (x/15.0) - math.floor(x/15.0)\n",
    "    return int(round(fractional*15))\n",
    "\n",
    "def make_lstm(gd):\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame(columns=gd.columns)\n",
    "    ids = gd.uhid.unique()\n",
    "    shuffle(ids)\n",
    "    for i in ids:\n",
    "        x = gd[gd['uhid']==i]\n",
    "        x = x[range_finder(len(x)):len(x)]\n",
    "\n",
    "        final_df = final_df.append(x,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    final_df.fillna(-999,inplace=True)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    death_cases = final_df[final_df.dischargestatus == 1]\n",
    "    discharge_cases = final_df[final_df.dischargestatus == 0]\n",
    "    \n",
    "    train_death = death_cases[:split_70(len(death_cases))]\n",
    "    test_death = death_cases[split_70(len(death_cases)):]\n",
    "    \n",
    "    train_discharge = discharge_cases[:split_70(len(discharge_cases))]\n",
    "    test_discharge = discharge_cases[split_70(len(discharge_cases)):]\n",
    "    \n",
    "    train = pd.concat([train_death,train_discharge])\n",
    "    test = pd.concat([test_death,test_discharge])\n",
    "\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    y_train = train['dischargestatus']\n",
    "    X_train = train.drop('dischargestatus',axis=1)\n",
    "    X_train = X_train.drop('uhid',axis=1)\n",
    "    #X_train = X_train.drop('visittime',axis=1)\n",
    "\n",
    "    y_test = test['dischargestatus']\n",
    "    X_test = test.drop('dischargestatus',axis=1)\n",
    "    X_test = X_test.drop('uhid',axis=1)\n",
    "    #X_test = X_test.drop('startdate',axis=1)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    auc_roc_inter = []\n",
    "    val_a = []\n",
    "    train_a = []\n",
    "\n",
    "\n",
    "    #converting the data into a numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    ytrain1 = []\n",
    "    for i in range(0,len(y_train),15):\n",
    "        #print(i)\n",
    "        y1 = y_train[i:i+15]\n",
    "        ytrain1.append(y1[-1])\n",
    "\n",
    "    ytest1 = []\n",
    "    for i in range(0,len(y_test),15):\n",
    "        #print(i)\n",
    "        y1 = y_test[i:i+15]\n",
    "        ytest1.append(y1[-1])\n",
    "\n",
    "    ytrain1 = np.array(ytrain1)\n",
    "    ytest1 = np.array(ytest1)\n",
    "\n",
    "    Xtrain = np.reshape(X_train, (-1, 15, X_train.shape[1]))\n",
    "    Xtest = np.reshape(X_test, (-1, 15, X_test.shape[1]))\n",
    "\n",
    "    return Xtrain,Xtest,ytrain1,ytest1\n",
    "\n",
    "def lstm_model(n,Xtrain,Xtest,ytrain1,ytest1):\n",
    "    auc_roc_inter = []\n",
    "    val_a = []\n",
    "    train_a = []\n",
    "    for i in range(2):\n",
    "        #Building the LSTM model\n",
    "        X = Input(shape=(None, n), name='X')\n",
    "        mX = Masking()(X)\n",
    "        lstm = Bidirectional(LSTM(units=512,activation='tanh',return_sequences=True,recurrent_dropout=0.5,dropout=0.3))\n",
    "        mX = lstm(mX)\n",
    "        L = LSTM(units=64,activation='tanh',return_sequences=False)(mX)\n",
    "        y = Dense(1, activation=\"sigmoid\")(L)\n",
    "        outputs = [y]\n",
    "        inputs = [X]\n",
    "        model = Model(inputs,outputs)\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "        v_a = []\n",
    "        t_a = []\n",
    "        #fitting the model\n",
    "        model.fit(Xtrain, ytrain1, batch_size=60 ,validation_split=0.15,epochs=38,callbacks=[es])\n",
    "        #history = model.fit(Xtrain, ytrain1, batch_size=60 ,validation_split=0.15,epochs=38,callbacks=[es])\n",
    "        for i in range(len(model.history.history['val_accuracy'])):\n",
    "            v_a.append(model.history.history['val_accuracy'][i])\n",
    "            t_a.append(model.history.history['accuracy'][i])\n",
    "        #predictions\n",
    "        y_pred = model.predict(Xtest)\n",
    "        #y_pred = y_pred.round()\n",
    "        y_test = np.array(ytest1)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_test = pd.DataFrame(y_test)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        def acc(x):\n",
    "            if x>0.5:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        y_model=[]\n",
    "        for i in y_pred:\n",
    "            y_model.append(acc(i))\n",
    "        y_answer=[]\n",
    "        for j in y_test:\n",
    "            y_answer.append(acc(j))\n",
    "            \n",
    "        val_a.append(v_a)\n",
    "        train_a.append(t_a)\n",
    "        auc_roc_inter.append(roc_auc_score(y_answer,y_pred))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "        \n",
    "    return auc_roc_inter,y_model,y_answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38816 samples, validate on 6850 samples\n",
      "Epoch 1/38\n",
      "38816/38816 [==============================] - 526s 14ms/step - loss: 0.6176 - accuracy: 0.6628 - val_loss: 0.9215 - val_accuracy: 0.1985\n",
      "Epoch 2/38\n",
      "38816/38816 [==============================] - 453s 12ms/step - loss: 0.5943 - accuracy: 0.6977 - val_loss: 0.9718 - val_accuracy: 0.1984\n",
      "Epoch 3/38\n",
      "38816/38816 [==============================] - 441s 11ms/step - loss: 0.5905 - accuracy: 0.7046 - val_loss: 0.9224 - val_accuracy: 0.1984\n",
      "Epoch 4/38\n",
      "38816/38816 [==============================] - 476s 12ms/step - loss: 0.5879 - accuracy: 0.7061 - val_loss: 1.0044 - val_accuracy: 0.1562\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00004: early stopping\n",
      "Train on 38816 samples, validate on 6850 samples\n",
      "Epoch 1/38\n",
      "38816/38816 [==============================] - 446s 11ms/step - loss: 0.6220 - accuracy: 0.6507 - val_loss: 0.8722 - val_accuracy: 0.3248\n",
      "Epoch 2/38\n",
      "38816/38816 [==============================] - 382s 10ms/step - loss: 0.6051 - accuracy: 0.6783 - val_loss: 0.8762 - val_accuracy: 0.3107\n",
      "Epoch 3/38\n",
      "38816/38816 [==============================] - 367s 9ms/step - loss: 0.6014 - accuracy: 0.6802 - val_loss: 0.8303 - val_accuracy: 0.2825\n",
      "Epoch 4/38\n",
      "38816/38816 [==============================] - 326s 8ms/step - loss: 0.5987 - accuracy: 0.6833 - val_loss: 1.0714 - val_accuracy: 0.1210\n",
      "Epoch 5/38\n",
      "38816/38816 [==============================] - 556s 14ms/step - loss: 0.5984 - accuracy: 0.6855 - val_loss: 0.8239 - val_accuracy: 0.3107\n",
      "Epoch 6/38\n",
      "38816/38816 [==============================] - 427s 11ms/step - loss: 0.5980 - accuracy: 0.6832 - val_loss: 0.7664 - val_accuracy: 0.3390\n",
      "Epoch 7/38\n",
      "38816/38816 [==============================] - 331s 9ms/step - loss: 0.5971 - accuracy: 0.6845 - val_loss: 0.9583 - val_accuracy: 0.2404\n",
      "Epoch 8/38\n",
      "38816/38816 [==============================] - 440s 11ms/step - loss: 0.5987 - accuracy: 0.6804 - val_loss: 0.6562 - val_accuracy: 0.3248\n",
      "Epoch 9/38\n",
      "38816/38816 [==============================] - 441s 11ms/step - loss: 0.5983 - accuracy: 0.6810 - val_loss: 1.0141 - val_accuracy: 0.1982\n",
      "Epoch 10/38\n",
      "38816/38816 [==============================] - 475s 12ms/step - loss: 0.5970 - accuracy: 0.6846 - val_loss: 0.9340 - val_accuracy: 0.1564\n",
      "Epoch 11/38\n",
      "38816/38816 [==============================] - 447s 12ms/step - loss: 0.5959 - accuracy: 0.6871 - val_loss: 0.9803 - val_accuracy: 0.1282\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','currentdateweight','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_a = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 9s 4ms/step - loss: 0.4239 - accuracy: 0.8414 - val_loss: 0.4355 - val_accuracy: 0.7950\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3915 - accuracy: 0.8590 - val_loss: 0.5323 - val_accuracy: 0.7950\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3749 - accuracy: 0.8590 - val_loss: 0.5607 - val_accuracy: 0.7950\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3756 - accuracy: 0.8590 - val_loss: 0.5149 - val_accuracy: 0.7950\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00004: early stopping\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 9s 4ms/step - loss: 0.4194 - accuracy: 0.8338 - val_loss: 0.5681 - val_accuracy: 0.7950\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3803 - accuracy: 0.8590 - val_loss: 0.5595 - val_accuracy: 0.6325\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3714 - accuracy: 0.8590 - val_loss: 0.5929 - val_accuracy: 0.8050\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3762 - accuracy: 0.8555 - val_loss: 0.5949 - val_accuracy: 0.8500\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3693 - accuracy: 0.8595 - val_loss: 0.5308 - val_accuracy: 0.7950\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3690 - accuracy: 0.8604 - val_loss: 0.6604 - val_accuracy: 0.5650\n",
      "Epoch 7/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3680 - accuracy: 0.8599 - val_loss: 0.7112 - val_accuracy: 0.5525\n",
      "Epoch 8/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3639 - accuracy: 0.8621 - val_loss: 0.7350 - val_accuracy: 0.4150\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','currentdateheight','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_b = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 9s 4ms/step - loss: 0.3940 - accuracy: 0.8308 - val_loss: 0.2259 - val_accuracy: 0.8350\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3681 - accuracy: 0.8515 - val_loss: 0.2600 - val_accuracy: 0.8350\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3595 - accuracy: 0.8573 - val_loss: 0.2575 - val_accuracy: 0.8375\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3670 - accuracy: 0.8506 - val_loss: 0.2341 - val_accuracy: 0.8375\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00004: early stopping\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 10s 4ms/step - loss: 0.3813 - accuracy: 0.8484 - val_loss: 0.2246 - val_accuracy: 0.9525\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3644 - accuracy: 0.8524 - val_loss: 0.2229 - val_accuracy: 0.8350\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3613 - accuracy: 0.8577 - val_loss: 0.2419 - val_accuracy: 0.8350\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3654 - accuracy: 0.8524 - val_loss: 0.2437 - val_accuracy: 0.8375\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3578 - accuracy: 0.8621 - val_loss: 0.2340 - val_accuracy: 0.8375\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','ph','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_c = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 10s 4ms/step - loss: 0.6547 - accuracy: 0.8674 - val_loss: 0.6403 - val_accuracy: 0.8900\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6363 - accuracy: 0.8710 - val_loss: 0.6269 - val_accuracy: 0.8900\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6186 - accuracy: 0.8657 - val_loss: 0.6017 - val_accuracy: 0.8900\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6114 - accuracy: 0.8692 - val_loss: 0.5954 - val_accuracy: 0.8900\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5950 - accuracy: 0.8626 - val_loss: 0.6013 - val_accuracy: 0.8900\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5861 - accuracy: 0.8692 - val_loss: 0.5696 - val_accuracy: 0.8900\n",
      "Epoch 7/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5750 - accuracy: 0.8692 - val_loss: 0.5463 - val_accuracy: 0.8900\n",
      "Epoch 8/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5650 - accuracy: 0.8727 - val_loss: 0.5622 - val_accuracy: 0.8900\n",
      "Epoch 9/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5520 - accuracy: 0.8767 - val_loss: 0.5328 - val_accuracy: 0.8875\n",
      "Epoch 10/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5437 - accuracy: 0.8811 - val_loss: 0.5422 - val_accuracy: 0.8875\n",
      "Epoch 11/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5399 - accuracy: 0.8736 - val_loss: 0.5287 - val_accuracy: 0.8900\n",
      "Epoch 12/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5282 - accuracy: 0.8802 - val_loss: 0.5013 - val_accuracy: 0.9175\n",
      "Epoch 13/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5204 - accuracy: 0.8749 - val_loss: 0.5165 - val_accuracy: 0.8900\n",
      "Epoch 14/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5136 - accuracy: 0.8758 - val_loss: 0.4997 - val_accuracy: 0.8900\n",
      "Epoch 15/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5066 - accuracy: 0.8749 - val_loss: 0.4979 - val_accuracy: 0.8925\n",
      "Epoch 16/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5021 - accuracy: 0.8758 - val_loss: 0.4820 - val_accuracy: 0.8925\n",
      "Epoch 17/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4909 - accuracy: 0.8758 - val_loss: 0.4778 - val_accuracy: 0.8900\n",
      "Epoch 18/38\n",
      "2263/2263 [==============================] - 5s 2ms/step - loss: 0.4828 - accuracy: 0.8763 - val_loss: 0.4727 - val_accuracy: 0.8900\n",
      "Epoch 19/38\n",
      "2263/2263 [==============================] - 5s 2ms/step - loss: 0.4787 - accuracy: 0.8701 - val_loss: 0.4653 - val_accuracy: 0.8900\n",
      "Epoch 20/38\n",
      "2263/2263 [==============================] - 5s 2ms/step - loss: 0.4691 - accuracy: 0.8763 - val_loss: 0.4709 - val_accuracy: 0.8900\n",
      "Epoch 21/38\n",
      "2263/2263 [==============================] - 5s 2ms/step - loss: 0.4677 - accuracy: 0.8754 - val_loss: 0.4577 - val_accuracy: 0.8900\n",
      "Epoch 22/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4581 - accuracy: 0.8816 - val_loss: 0.4485 - val_accuracy: 0.8900\n",
      "Epoch 23/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4580 - accuracy: 0.8789 - val_loss: 0.4451 - val_accuracy: 0.8900\n",
      "Epoch 24/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4434 - accuracy: 0.8869 - val_loss: 0.4457 - val_accuracy: 0.8900\n",
      "Epoch 25/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4457 - accuracy: 0.8802 - val_loss: 0.4364 - val_accuracy: 0.8900\n",
      "Epoch 26/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4456 - accuracy: 0.8741 - val_loss: 0.4292 - val_accuracy: 0.8900\n",
      "Epoch 27/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4347 - accuracy: 0.8811 - val_loss: 0.4284 - val_accuracy: 0.8900\n",
      "Epoch 28/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4256 - accuracy: 0.8829 - val_loss: 0.4180 - val_accuracy: 0.8900\n",
      "Epoch 29/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4280 - accuracy: 0.8785 - val_loss: 0.4149 - val_accuracy: 0.8900\n",
      "Epoch 30/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4184 - accuracy: 0.8891 - val_loss: 0.3956 - val_accuracy: 0.8900\n",
      "Epoch 31/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4174 - accuracy: 0.8789 - val_loss: 0.4044 - val_accuracy: 0.8900\n",
      "Epoch 32/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4121 - accuracy: 0.8794 - val_loss: 0.4232 - val_accuracy: 0.8900\n",
      "Epoch 33/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4042 - accuracy: 0.8851 - val_loss: 0.3920 - val_accuracy: 0.8900\n",
      "Epoch 34/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3987 - accuracy: 0.8847 - val_loss: 0.3943 - val_accuracy: 0.8900\n",
      "Epoch 35/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4046 - accuracy: 0.8754 - val_loss: 0.3803 - val_accuracy: 0.8900\n",
      "Epoch 36/38\n",
      "2263/2263 [==============================] - 6s 2ms/step - loss: 0.4007 - accuracy: 0.8758 - val_loss: 0.3737 - val_accuracy: 0.8900\n",
      "Epoch 37/38\n",
      "2263/2263 [==============================] - 5s 2ms/step - loss: 0.3915 - accuracy: 0.8780 - val_loss: 0.3727 - val_accuracy: 0.8900\n",
      "Epoch 38/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3924 - accuracy: 0.8807 - val_loss: 0.3678 - val_accuracy: 0.8925\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 10s 4ms/step - loss: 0.6601 - accuracy: 0.8533 - val_loss: 0.6444 - val_accuracy: 0.8900\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6422 - accuracy: 0.8626 - val_loss: 0.6222 - val_accuracy: 0.8900\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6194 - accuracy: 0.8749 - val_loss: 0.6092 - val_accuracy: 0.8900\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6150 - accuracy: 0.8617 - val_loss: 0.5975 - val_accuracy: 0.8900\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.6010 - accuracy: 0.8688 - val_loss: 0.5876 - val_accuracy: 0.8900\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5904 - accuracy: 0.8604 - val_loss: 0.5745 - val_accuracy: 0.8900\n",
      "Epoch 7/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5767 - accuracy: 0.8701 - val_loss: 0.5579 - val_accuracy: 0.9150\n",
      "Epoch 8/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5693 - accuracy: 0.8710 - val_loss: 0.5500 - val_accuracy: 0.8900\n",
      "Epoch 9/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5538 - accuracy: 0.8794 - val_loss: 0.5505 - val_accuracy: 0.8900\n",
      "Epoch 10/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5493 - accuracy: 0.8692 - val_loss: 0.5318 - val_accuracy: 0.8900\n",
      "Epoch 11/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5405 - accuracy: 0.8679 - val_loss: 0.5237 - val_accuracy: 0.8900\n",
      "Epoch 12/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5339 - accuracy: 0.8665 - val_loss: 0.5136 - val_accuracy: 0.8875\n",
      "Epoch 13/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5310 - accuracy: 0.8679 - val_loss: 0.5098 - val_accuracy: 0.8900\n",
      "Epoch 14/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5128 - accuracy: 0.8683 - val_loss: 0.4978 - val_accuracy: 0.8900\n",
      "Epoch 15/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5126 - accuracy: 0.8736 - val_loss: 0.4928 - val_accuracy: 0.8900\n",
      "Epoch 16/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.5008 - accuracy: 0.8688 - val_loss: 0.4779 - val_accuracy: 0.8900\n",
      "Epoch 17/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4937 - accuracy: 0.8723 - val_loss: 0.4739 - val_accuracy: 0.8900\n",
      "Epoch 18/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4872 - accuracy: 0.8767 - val_loss: 0.4656 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4824 - accuracy: 0.8767 - val_loss: 0.4728 - val_accuracy: 0.8900\n",
      "Epoch 20/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4740 - accuracy: 0.8794 - val_loss: 0.4658 - val_accuracy: 0.8900\n",
      "Epoch 21/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4683 - accuracy: 0.8749 - val_loss: 0.4634 - val_accuracy: 0.8900\n",
      "Epoch 22/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4588 - accuracy: 0.8838 - val_loss: 0.4532 - val_accuracy: 0.8900\n",
      "Epoch 23/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4493 - accuracy: 0.8886 - val_loss: 0.4400 - val_accuracy: 0.8900\n",
      "Epoch 24/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4534 - accuracy: 0.8727 - val_loss: 0.4349 - val_accuracy: 0.8900\n",
      "Epoch 25/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4483 - accuracy: 0.8719 - val_loss: 0.4192 - val_accuracy: 0.8900\n",
      "Epoch 26/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4445 - accuracy: 0.8772 - val_loss: 0.4180 - val_accuracy: 0.8900\n",
      "Epoch 27/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4398 - accuracy: 0.8767 - val_loss: 0.4129 - val_accuracy: 0.8900\n",
      "Epoch 28/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4311 - accuracy: 0.8745 - val_loss: 0.4049 - val_accuracy: 0.8900\n",
      "Epoch 29/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4311 - accuracy: 0.8723 - val_loss: 0.4079 - val_accuracy: 0.8900\n",
      "Epoch 30/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4233 - accuracy: 0.8820 - val_loss: 0.4016 - val_accuracy: 0.8875\n",
      "Epoch 31/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4165 - accuracy: 0.8825 - val_loss: 0.4021 - val_accuracy: 0.8900\n",
      "Epoch 32/38\n",
      "2263/2263 [==============================] - 6s 2ms/step - loss: 0.4184 - accuracy: 0.8758 - val_loss: 0.3938 - val_accuracy: 0.8900\n",
      "Epoch 33/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4072 - accuracy: 0.8842 - val_loss: 0.3939 - val_accuracy: 0.8900\n",
      "Epoch 34/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3998 - accuracy: 0.8917 - val_loss: 0.3897 - val_accuracy: 0.8900\n",
      "Epoch 35/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3986 - accuracy: 0.8864 - val_loss: 0.3846 - val_accuracy: 0.8875\n",
      "Epoch 36/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3960 - accuracy: 0.8802 - val_loss: 0.3796 - val_accuracy: 0.8900\n",
      "Epoch 37/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3938 - accuracy: 0.8789 - val_loss: 0.3753 - val_accuracy: 0.8900\n",
      "Epoch 38/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.3848 - accuracy: 0.8860 - val_loss: 0.3807 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','tpn-tfl','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_d = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 2ms/step - loss: 0.4520 - accuracy: 0.8378 - val_loss: 0.2617 - val_accuracy: 0.9575\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4250 - accuracy: 0.8436 - val_loss: 0.3237 - val_accuracy: 0.9575\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4250 - accuracy: 0.8422 - val_loss: 0.2651 - val_accuracy: 0.9600\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4242 - accuracy: 0.8462 - val_loss: 0.3180 - val_accuracy: 0.9600\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00004: early stopping\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 2ms/step - loss: 0.4457 - accuracy: 0.8427 - val_loss: 0.2087 - val_accuracy: 0.9600\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4253 - accuracy: 0.8462 - val_loss: 0.2783 - val_accuracy: 0.9600\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4232 - accuracy: 0.8436 - val_loss: 0.2186 - val_accuracy: 0.9600\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.4214 - accuracy: 0.8462 - val_loss: 0.2974 - val_accuracy: 0.9600\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','rbs','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_e = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 2ms/step - loss: 0.2786 - accuracy: 0.8856 - val_loss: 0.7497 - val_accuracy: 0.6975\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2557 - accuracy: 0.9085 - val_loss: 0.7461 - val_accuracy: 0.7550\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2501 - accuracy: 0.9342 - val_loss: 0.6768 - val_accuracy: 0.7550\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2494 - accuracy: 0.9342 - val_loss: 0.6836 - val_accuracy: 0.7550\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2520 - accuracy: 0.9342 - val_loss: 0.7042 - val_accuracy: 0.7550\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2500 - accuracy: 0.9342 - val_loss: 0.7995 - val_accuracy: 0.7550\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.2781 - accuracy: 0.8992 - val_loss: 0.7808 - val_accuracy: 0.6975\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2586 - accuracy: 0.9099 - val_loss: 0.7975 - val_accuracy: 0.7550\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2507 - accuracy: 0.9342 - val_loss: 0.7838 - val_accuracy: 0.7550\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2538 - accuracy: 0.9342 - val_loss: 0.7656 - val_accuracy: 0.7550\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2471 - accuracy: 0.9342 - val_loss: 0.9066 - val_accuracy: 0.7550\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2525 - accuracy: 0.9342 - val_loss: 0.8320 - val_accuracy: 0.7550\n",
      "Epoch 7/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2493 - accuracy: 0.9342 - val_loss: 0.7069 - val_accuracy: 0.7550\n",
      "Epoch 8/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2529 - accuracy: 0.9342 - val_loss: 0.7476 - val_accuracy: 0.7550\n",
      "Epoch 9/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2469 - accuracy: 0.9337 - val_loss: 0.7934 - val_accuracy: 0.7550\n",
      "Epoch 10/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.2454 - accuracy: 0.9337 - val_loss: 0.8036 - val_accuracy: 0.7550\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','stool_day_total','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_f = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4352 - accuracy: 0.8621 - val_loss: 0.1801 - val_accuracy: 0.9850\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3812 - accuracy: 0.8736 - val_loss: 0.1749 - val_accuracy: 0.9850\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3809 - accuracy: 0.8736 - val_loss: 0.1896 - val_accuracy: 0.9850\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3802 - accuracy: 0.8736 - val_loss: 0.1635 - val_accuracy: 0.9850\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3799 - accuracy: 0.8736 - val_loss: 0.1477 - val_accuracy: 0.9850\n",
      "Epoch 6/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3797 - accuracy: 0.8736 - val_loss: 0.1631 - val_accuracy: 0.9850\n",
      "Epoch 7/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3802 - accuracy: 0.8736 - val_loss: 0.1821 - val_accuracy: 0.9850\n",
      "Epoch 8/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3821 - accuracy: 0.8736 - val_loss: 0.1732 - val_accuracy: 0.9850\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "Train on 2263 samples, validate on 400 samples\n",
      "Epoch 1/38\n",
      "2263/2263 [==============================] - 6s 3ms/step - loss: 0.4318 - accuracy: 0.8723 - val_loss: 0.1511 - val_accuracy: 0.9850\n",
      "Epoch 2/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3804 - accuracy: 0.8736 - val_loss: 0.1488 - val_accuracy: 0.9850\n",
      "Epoch 3/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3803 - accuracy: 0.8732 - val_loss: 0.1542 - val_accuracy: 0.9850\n",
      "Epoch 4/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3794 - accuracy: 0.8736 - val_loss: 0.1809 - val_accuracy: 0.9850\n",
      "Epoch 5/38\n",
      "2263/2263 [==============================] - 4s 2ms/step - loss: 0.3815 - accuracy: 0.8736 - val_loss: 0.1737 - val_accuracy: 0.9850\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['uhid','urine_per_kg_hour','dischargestatus']\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model((len(cols_to_use)-2),Xtrain,Xtest,ytrain1,ytest1)\n",
    "a_g = mean_confidence_interval(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|  Parameter   |        AUC-ROC        |\n",
      "+--------------+-----------------------+\n",
      "| Daily Weight | (0.933, 0.929, 0.937) |\n",
      "| Daily Length |  (0.79, 0.018, 1.563) |\n",
      "|      pH      | (0.735, 0.732, 0.737) |\n",
      "|   TPN/TFL    | (0.564, 0.467, 0.661) |\n",
      "|     RBS      | (0.576, 0.469, 0.683) |\n",
      "|    Stool     |  (0.64, 0.636, 0.643) |\n",
      "| Urine/kg/Hr  | (0.545, 0.434, 0.656) |\n",
      "+--------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "l = [[\"Daily Weight\" ,a_a],[\"Daily Length\" ,a_b],[\"pH\" ,a_c],[\"TPN/TFL\" ,a_d],[\"RBS\" ,a_e],[\"Stool\" ,a_f],[\"Urine/kg/Hr\" ,a_g]]\n",
    "\n",
    "table = PrettyTable(['Parameter', 'AUC-ROC'])\n",
    "\n",
    "for rec in l:\n",
    "    table.add_row(rec)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
