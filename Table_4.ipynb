{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Activation, Dense, Dropout, SpatialDropout1D,Input,Masking,Bidirectional, TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import seed\n",
    "#seed(1)\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "#defining the early stopping criteria\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,restore_best_weights=True,patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = pd.read_csv('LSTM_1_hour_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['uhid','pulserate', 'ecg_resprate',\n",
    "       'spo2', 'heartrate', 'mean_bp', 'sys_bp', 'dia_bp',\n",
    "       'peep', 'pip', 'map', 'tidalvol', 'minvol', 'ti', 'fio2',\n",
    "       'abd_difference_y',\n",
    "       'abdomen_girth_y','currentdateheight',\n",
    "       'currentdateweight','dischargestatus', \n",
    "       'new_ph', \n",
    "       'rbs',  'stool_day_total', \n",
    "       'temp', 'total_intake', 'totalparenteralvolume',\n",
    "       'tpn-tfl', 'typevalue_Antibiotics', 'typevalue_Inotropes',\n",
    "       'urine', 'urine_per_hour',\n",
    "       'urine_per_kg_hour','gender', 'birthweight',\n",
    "       'birthlength', 'birthheadcircumference', 'inout_patient_status',\n",
    "       'gestationweekbylmp', 'gestationdaysbylmp',\n",
    "       'baby_type', 'central_temp', 'apgar_onemin', 'apgar_fivemin',\n",
    "       'apgar_tenmin', 'motherage', 'conception_type', 'mode_of_delivery',\n",
    "       'steroidname', 'numberofdose', 'gestation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_finder(p):\n",
    "    length = p\n",
    "    fractional = (p/15.0) - math.floor(p/15.0)\n",
    "    return int(round(fractional*15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(u):\n",
    "    \n",
    "    f_df = pd.DataFrame(columns=u.columns)\n",
    "    for i in u.uhid.unique():\n",
    "        x = u[u['uhid']==i]\n",
    "        x = x[range_finder(len(x)):len(x)]\n",
    "\n",
    "        f_df = f_df.append(x,ignore_index=True)\n",
    "        \n",
    "        return f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = gs[cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm(gd):\n",
    "\n",
    "\n",
    "    final_df = gd.copy()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    final_df.fillna(-999,inplace=True)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    train = final_df[:2520]\n",
    "    test = final_df[2520:]\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    y_train = train['dischargestatus']\n",
    "    X_train = train.drop('dischargestatus',axis=1)\n",
    "    X_train = X_train.drop('uhid',axis=1)\n",
    "    #X_train = X_train.drop('visittime',axis=1)\n",
    "\n",
    "    y_test = test['dischargestatus']\n",
    "    X_test = test.drop('dischargestatus',axis=1)\n",
    "    X_test = X_test.drop('uhid',axis=1)\n",
    "    #X_test = X_test.drop('startdate',axis=1)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    auc_roc_inter = []\n",
    "    val_a = []\n",
    "    train_a = []\n",
    "\n",
    "\n",
    "    #converting the data into a numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    ytrain1 = []\n",
    "    for i in range(0,len(y_train),15):\n",
    "        #print(i)\n",
    "        y1 = y_train[i:i+15]\n",
    "        ytrain1.append(y1[-1])\n",
    "\n",
    "    ytest1 = []\n",
    "    for i in range(0,len(y_test),15):\n",
    "        #print(i)\n",
    "        y1 = y_test[i:i+15]\n",
    "        ytest1.append(y1[-1])\n",
    "\n",
    "    ytrain1 = np.array(ytrain1)\n",
    "    ytest1 = np.array(ytest1)\n",
    "\n",
    "    Xtrain = np.reshape(X_train, (-1, 15, X_train.shape[1]))\n",
    "    Xtest = np.reshape(X_test, (-1, 15, X_test.shape[1]))\n",
    "\n",
    "    return Xtrain,Xtest,ytrain1,ytest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(Xtrain,Xtest,ytrain1,ytest1):\n",
    "    auc_roc_inter = []\n",
    "    val_a = []\n",
    "    train_a = []\n",
    "    for i in range(2):\n",
    "        #Building the LSTM model\n",
    "        X = Input(shape=(None, 48), name='X')\n",
    "        mX = Masking()(X)\n",
    "        lstm = Bidirectional(LSTM(units=512,activation='tanh',return_sequences=True,recurrent_dropout=0.5,dropout=0.3))\n",
    "        mX = lstm(mX)\n",
    "        L = LSTM(units=64,activation='tanh',return_sequences=False)(mX)\n",
    "        y = Dense(1, activation=\"sigmoid\")(L)\n",
    "        outputs = [y]\n",
    "        inputs = [X]\n",
    "        model = Model(inputs,outputs)\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "        v_a = []\n",
    "        t_a = []\n",
    "        #fitting the model\n",
    "        model.fit(Xtrain, ytrain1, batch_size=60 ,validation_split=0.15,epochs=38,callbacks=[es])\n",
    "        #history = model.fit(Xtrain, ytrain1, batch_size=60 ,validation_split=0.15,epochs=38,callbacks=[es])\n",
    "        for i in range(len(model.history.history['val_accuracy'])):\n",
    "            v_a.append(model.history.history['val_accuracy'][i])\n",
    "            t_a.append(model.history.history['accuracy'][i])\n",
    "        #predictions\n",
    "        y_pred = model.predict(Xtest)\n",
    "        #y_pred = y_pred.round()\n",
    "        y_test = np.array(ytest1)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_test = pd.DataFrame(y_test)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        def acc(x):\n",
    "            if x>0.5:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        y_model=[]\n",
    "        for i in y_pred:\n",
    "            y_model.append(acc(i))\n",
    "        y_answer=[]\n",
    "        for j in y_test:\n",
    "            y_answer.append(acc(j))\n",
    "            \n",
    "        val_a.append(v_a)\n",
    "        train_a.append(t_a)\n",
    "        auc_roc_inter.append(roc_auc_score(y_answer,y_pred))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "        \n",
    "    return auc_roc_inter,y_model,y_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/inicuuser/.local/lib/python2.7/site-packages/tensorflow/python/keras/backend.py:3794: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/inicuuser/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 1s 11ms/step - loss: 0.6491 - accuracy: 0.5986 - val_loss: 0.7028 - val_accuracy: 0.5385\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.6831 - val_loss: 0.7359 - val_accuracy: 0.5769\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7746 - val_loss: 0.3643 - val_accuracy: 0.6923\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.9366 - val_loss: 0.1613 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8732 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9085 - val_loss: 0.2057 - val_accuracy: 0.8462\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9155 - val_loss: 0.3249 - val_accuracy: 0.6923\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9225 - val_loss: 0.1478 - val_accuracy: 0.9615\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.6482 - accuracy: 0.5775 - val_loss: 0.7416 - val_accuracy: 0.5385\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7042 - val_loss: 0.7015 - val_accuracy: 0.6923\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8451 - val_loss: 0.4238 - val_accuracy: 0.6923\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8803 - val_loss: 0.2912 - val_accuracy: 0.8462\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9014 - val_loss: 0.2862 - val_accuracy: 0.8462\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9085 - val_loss: 0.5042 - val_accuracy: 0.6923\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9296 - val_loss: 0.7818 - val_accuracy: 0.6923\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9014 - val_loss: 0.7507 - val_accuracy: 0.6923\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_a = mean_confidence_interval(an)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_1 = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_1 = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inicuuser/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (14,15,16,24,34,40,42,44,45,46,47,52,54,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_6_hour_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = gs[cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 0.6150 - accuracy: 0.6620 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8803 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9507 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9718 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9859 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9930 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9789 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9718 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9859 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 9.0329e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 9.6727e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9930 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 0.7085 - accuracy: 0.5282 - val_loss: 0.2273 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.9155 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.9225 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9296 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9718 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9577 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9930 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9789 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9789 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9789 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 8.9199e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9930 - val_loss: 7.6836e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 6.7934e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9930 - val_loss: 6.1470e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 5.6027e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9930 - val_loss: 5.3503e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 5.4464e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 5.7296e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9789 - val_loss: 6.2620e-04 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_6 = mean_confidence_interval(an)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_6 = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_6 = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inicuuser/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (14,15,16,24,34,40,41,42,44,45,46,47,52,54,56,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 0.6242 - accuracy: 0.6479 - val_loss: 1.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7183 - val_loss: 0.3657 - val_accuracy: 0.9231\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9225 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9930 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 8.5344e-04 - accuracy: 1.0000 - val_loss: 9.9504e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 7.5529e-04 - accuracy: 1.0000 - val_loss: 9.3204e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.8115e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 8.4043e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.2485e-04 - accuracy: 1.0000 - val_loss: 8.0809e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.9061e-04 - accuracy: 1.0000 - val_loss: 7.7967e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.5865e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 8.0487e-04 - accuracy: 1.0000 - val_loss: 7.3113e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.9669e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7968e-04 - accuracy: 1.0000 - val_loss: 6.5995e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.2705e-04 - accuracy: 1.0000 - val_loss: 6.0467e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9930 - val_loss: 5.9071e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.5808e-04 - accuracy: 1.0000 - val_loss: 6.0917e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.7863e-04 - accuracy: 1.0000 - val_loss: 6.3024e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9930 - val_loss: 6.3108e-04 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00030: early stopping\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 0.6268 - accuracy: 0.5986 - val_loss: 1.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.7887 - val_loss: 0.3190 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9437 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9930 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.4886e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 8.5201e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.9096e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.2052e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9930 - val_loss: 6.7154e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.1146e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 8.9415e-04 - accuracy: 1.0000 - val_loss: 5.7920e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 7.4745e-04 - accuracy: 1.0000 - val_loss: 5.2858e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.7843e-04 - accuracy: 1.0000 - val_loss: 5.0279e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.0608e-04 - accuracy: 1.0000 - val_loss: 4.7572e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.0749e-04 - accuracy: 1.0000 - val_loss: 4.5781e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 3ms/step - loss: 5.5501e-04 - accuracy: 1.0000 - val_loss: 4.4174e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.9469e-04 - accuracy: 1.0000 - val_loss: 4.2162e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.8580e-04 - accuracy: 1.0000 - val_loss: 3.8985e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.3440e-04 - accuracy: 1.0000 - val_loss: 3.7136e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 8.0894e-04 - accuracy: 1.0000 - val_loss: 3.5882e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.7857e-04 - accuracy: 1.0000 - val_loss: 3.3675e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.8510e-04 - accuracy: 1.0000 - val_loss: 3.1697e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.8059e-04 - accuracy: 1.0000 - val_loss: 2.9781e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.0589e-04 - accuracy: 1.0000 - val_loss: 2.6981e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 4.9749e-04 - accuracy: 1.0000 - val_loss: 2.5444e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 3.9814e-04 - accuracy: 1.0000 - val_loss: 2.4664e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.1504e-04 - accuracy: 1.0000 - val_loss: 2.4212e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3564e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_12_hour_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_12 = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_12 = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_12 = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inicuuser/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (14,15,16,24,31,32,34,37,38,40,41,42,43,44,45,46,47,52,54,56,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.6342 - accuracy: 0.5352 - val_loss: 0.0968 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.7324 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2550 - accuracy: 0.9085 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 9.8599e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 8.2105e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 7.0415e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 6.2795e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 5.6734e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.2880e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.1096e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.0034e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 4.9618e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.8529e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7493e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7372e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9930 - val_loss: 4.6216e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.5189e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.3717e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.2231e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1221e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.9575e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7917e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.6969e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.5913e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.5704e-04 - accuracy: 1.0000 - val_loss: 3.4986e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.7176e-04 - accuracy: 1.0000 - val_loss: 3.3635e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.5400e-04 - accuracy: 1.0000 - val_loss: 3.2250e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.8056e-04 - accuracy: 1.0000 - val_loss: 3.1336e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.3800e-04 - accuracy: 1.0000 - val_loss: 3.0112e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.6326e-04 - accuracy: 1.0000 - val_loss: 2.9020e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 9.7058e-04 - accuracy: 1.0000 - val_loss: 2.8121e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.2620e-04 - accuracy: 1.0000 - val_loss: 2.6926e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.7825e-04 - accuracy: 1.0000 - val_loss: 2.5697e-04 - val_accuracy: 1.0000\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 5s 37ms/step - loss: 0.5813 - accuracy: 0.6338 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.7535 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2491 - accuracy: 0.8873 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9859 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 9.6817e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 8.0111e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 6.7281e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.9252e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.3149e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.8631e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.5853e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.2956e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0860e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8174e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 9.7282e-04 - accuracy: 1.0000 - val_loss: 3.5986e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 9.4820e-04 - accuracy: 1.0000 - val_loss: 3.4349e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 8.6089e-04 - accuracy: 1.0000 - val_loss: 3.2714e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 8.5222e-04 - accuracy: 1.0000 - val_loss: 3.1329e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.7968e-04 - accuracy: 1.0000 - val_loss: 3.0151e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.1958e-04 - accuracy: 1.0000 - val_loss: 2.9116e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 8.8574e-04 - accuracy: 1.0000 - val_loss: 2.8197e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.5730e-04 - accuracy: 1.0000 - val_loss: 2.7025e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.8059e-04 - accuracy: 1.0000 - val_loss: 2.5821e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 8.0077e-04 - accuracy: 1.0000 - val_loss: 2.5019e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 8.2397e-04 - accuracy: 1.0000 - val_loss: 2.4208e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.6956e-04 - accuracy: 1.0000 - val_loss: 2.3300e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 4.9847e-04 - accuracy: 1.0000 - val_loss: 2.2423e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.1006e-04 - accuracy: 1.0000 - val_loss: 2.1718e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9930 - val_loss: 2.1587e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.2050e-04 - accuracy: 1.0000 - val_loss: 2.2216e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9859 - val_loss: 2.2992e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9930 - val_loss: 2.4272e-04 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_48_hour_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_48 = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_48 = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_48 = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 5s 37ms/step - loss: 0.5924 - accuracy: 0.6831 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.7465 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2074 - accuracy: 0.9225 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9930 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9930 - val_loss: 6.6016e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9930 - val_loss: 4.7320e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.5897e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0311e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5884e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 2.3536e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3497e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2860e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.3621e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3155e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3669e-04 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 5s 37ms/step - loss: 0.6479 - accuracy: 0.5845 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.3981 - accuracy: 0.7254 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.2566 - accuracy: 0.9085 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 8.0378e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 6.9408e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.2213e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.4703e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.0129e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.6053e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.3385e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.9529e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.7307e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4699e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 8.5507e-04 - accuracy: 1.0000 - val_loss: 3.2848e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 7.9868e-04 - accuracy: 1.0000 - val_loss: 3.0644e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 7.4453e-04 - accuracy: 1.0000 - val_loss: 2.9307e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.7547e-04 - accuracy: 1.0000 - val_loss: 2.7748e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.5385e-04 - accuracy: 1.0000 - val_loss: 2.6601e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.5374e-04 - accuracy: 1.0000 - val_loss: 2.5201e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.3440e-04 - accuracy: 1.0000 - val_loss: 2.4076e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.1073e-04 - accuracy: 1.0000 - val_loss: 2.3113e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.2604e-04 - accuracy: 1.0000 - val_loss: 2.2402e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.8941e-04 - accuracy: 1.0000 - val_loss: 2.1510e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.2011e-04 - accuracy: 1.0000 - val_loss: 2.0740e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 6.0381e-04 - accuracy: 1.0000 - val_loss: 2.0424e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.2592e-04 - accuracy: 1.0000 - val_loss: 1.9972e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.6967e-04 - accuracy: 1.0000 - val_loss: 1.9116e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.8591e-04 - accuracy: 1.0000 - val_loss: 1.8353e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.4921e-04 - accuracy: 1.0000 - val_loss: 1.6938e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.2240e-04 - accuracy: 1.0000 - val_loss: 1.6259e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.1895e-04 - accuracy: 1.0000 - val_loss: 1.5868e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.5056e-04 - accuracy: 1.0000 - val_loss: 1.5372e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_1_week_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_1w = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_1w = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_1w = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 6s 41ms/step - loss: 0.5769 - accuracy: 0.6479 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2974 - accuracy: 0.8451 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1281 - accuracy: 0.9789 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 8.0677e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.9767e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.6230e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.0075e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6692e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4464e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.9793e-04 - accuracy: 1.0000 - val_loss: 1.2459e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1277e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.4726e-04 - accuracy: 1.0000 - val_loss: 1.0200e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.1194e-04 - accuracy: 1.0000 - val_loss: 9.2529e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.8672e-04 - accuracy: 1.0000 - val_loss: 8.5682e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.0884e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.7232e-04 - accuracy: 1.0000 - val_loss: 7.8215e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.9380e-04 - accuracy: 1.0000 - val_loss: 7.5105e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.3252e-04 - accuracy: 1.0000 - val_loss: 7.1309e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.8497e-04 - accuracy: 1.0000 - val_loss: 6.8159e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.9248e-04 - accuracy: 1.0000 - val_loss: 6.5558e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.9690e-04 - accuracy: 1.0000 - val_loss: 6.2791e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.3216e-04 - accuracy: 1.0000 - val_loss: 6.0825e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.2434e-04 - accuracy: 1.0000 - val_loss: 5.9024e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.7727e-04 - accuracy: 1.0000 - val_loss: 5.7641e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.2095e-04 - accuracy: 1.0000 - val_loss: 5.5860e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.1567e-04 - accuracy: 1.0000 - val_loss: 5.4773e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.0723e-04 - accuracy: 1.0000 - val_loss: 5.3825e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.8089e-04 - accuracy: 1.0000 - val_loss: 5.2123e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.1649e-04 - accuracy: 1.0000 - val_loss: 5.1027e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 2.1596e-04 - accuracy: 1.0000 - val_loss: 4.9364e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.5749e-04 - accuracy: 1.0000 - val_loss: 4.8095e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.5609e-04 - accuracy: 1.0000 - val_loss: 4.8025e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 2.6756e-04 - accuracy: 1.0000 - val_loss: 4.6248e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.5285e-04 - accuracy: 1.0000 - val_loss: 4.3926e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.7915e-04 - accuracy: 1.0000 - val_loss: 4.2347e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.4410e-04 - accuracy: 1.0000 - val_loss: 4.1691e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.5027e-04 - accuracy: 1.0000 - val_loss: 4.1230e-05 - val_accuracy: 1.0000\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 6s 42ms/step - loss: 0.6391 - accuracy: 0.5986 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.7535 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.9155 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9859 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 9.2087e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 7.5930e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 6.1252e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.1693e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5995e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1705e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.8310e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.5577e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2020e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0374e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.7522e-04 - accuracy: 1.0000 - val_loss: 2.9012e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.9898e-04 - accuracy: 1.0000 - val_loss: 2.7943e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.9520e-04 - accuracy: 1.0000 - val_loss: 2.6952e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.4522e-04 - accuracy: 1.0000 - val_loss: 2.6051e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4698e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3262e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.0179e-04 - accuracy: 1.0000 - val_loss: 2.2241e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2232e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.8376e-04 - accuracy: 1.0000 - val_loss: 2.1887e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1589e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.1050e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0383e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9533e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.7941e-04 - accuracy: 1.0000 - val_loss: 1.8848e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.8808e-04 - accuracy: 1.0000 - val_loss: 1.8393e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.6047e-04 - accuracy: 1.0000 - val_loss: 1.7969e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7223e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.9809e-04 - accuracy: 1.0000 - val_loss: 1.6717e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.9905e-04 - accuracy: 1.0000 - val_loss: 1.6276e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 4.0346e-04 - accuracy: 1.0000 - val_loss: 1.5836e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 4.1199e-04 - accuracy: 1.0000 - val_loss: 1.5347e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_2_week.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_2w = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_2w = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_2w = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 6s 44ms/step - loss: 0.5537 - accuracy: 0.7254 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.3324 - accuracy: 0.8310 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9577 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9930 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 9.9791e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.3078e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 7.2962e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.4222e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.8331e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.3569e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9930 - val_loss: 4.9510e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.6337e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.3351e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1584e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0033e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.7860e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.5478e-04 - accuracy: 1.0000 - val_loss: 3.5906e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.7104e-04 - accuracy: 1.0000 - val_loss: 3.4669e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.7104e-04 - accuracy: 1.0000 - val_loss: 3.3512e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.9450e-04 - accuracy: 1.0000 - val_loss: 3.1451e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9684e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.3566e-04 - accuracy: 1.0000 - val_loss: 2.8755e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.5082e-04 - accuracy: 1.0000 - val_loss: 2.7744e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.1529e-04 - accuracy: 1.0000 - val_loss: 2.7039e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6227e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9930 - val_loss: 2.5662e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.6290e-04 - accuracy: 1.0000 - val_loss: 2.4937e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.1657e-04 - accuracy: 1.0000 - val_loss: 2.4662e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4166e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.9050e-04 - accuracy: 1.0000 - val_loss: 2.3736e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3280e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2615e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.3769e-04 - accuracy: 1.0000 - val_loss: 2.2227e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9930 - val_loss: 2.1521e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 7.2823e-04 - accuracy: 1.0000 - val_loss: 2.1110e-04 - val_accuracy: 1.0000\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.5756 - accuracy: 0.6408 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.7606 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1836 - accuracy: 0.9789 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9859 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 7.4336e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.3454e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.0813e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.3375e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8660e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4927e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2481e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0809e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.0649e-04 - accuracy: 1.0000 - val_loss: 1.8618e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 6.0220e-04 - accuracy: 1.0000 - val_loss: 1.7439e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.2722e-04 - accuracy: 1.0000 - val_loss: 1.6510e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.3029e-04 - accuracy: 1.0000 - val_loss: 1.5564e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 5.0319e-04 - accuracy: 1.0000 - val_loss: 1.4915e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 4.2498e-04 - accuracy: 1.0000 - val_loss: 1.4180e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.5138e-04 - accuracy: 1.0000 - val_loss: 1.3502e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3024e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 3.8503e-04 - accuracy: 1.0000 - val_loss: 1.2618e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.9992e-04 - accuracy: 1.0000 - val_loss: 1.2240e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 5.6682e-04 - accuracy: 1.0000 - val_loss: 1.1814e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 4.2559e-04 - accuracy: 1.0000 - val_loss: 1.1782e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.6230e-04 - accuracy: 1.0000 - val_loss: 1.1352e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.4989e-04 - accuracy: 1.0000 - val_loss: 1.1073e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 2.8634e-04 - accuracy: 1.0000 - val_loss: 1.0821e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.2477e-04 - accuracy: 1.0000 - val_loss: 1.0573e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 2.8788e-04 - accuracy: 1.0000 - val_loss: 1.0309e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 3.2739e-04 - accuracy: 1.0000 - val_loss: 1.0018e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 2.6830e-04 - accuracy: 1.0000 - val_loss: 9.6655e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 2.5980e-04 - accuracy: 1.0000 - val_loss: 9.2516e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 2.4986e-04 - accuracy: 1.0000 - val_loss: 8.7471e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 2.8703e-04 - accuracy: 1.0000 - val_loss: 8.4058e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 2.2643e-04 - accuracy: 1.0000 - val_loss: 8.0776e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 2.2777e-04 - accuracy: 1.0000 - val_loss: 7.8626e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_3_week_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_3w = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_3w = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_3w = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.6347 - accuracy: 0.5986 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.7254 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2604 - accuracy: 0.8521 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9930 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 8.9491e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9930 - val_loss: 6.7656e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.7619e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.9127e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.2265e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.7257e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.3665e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.1487e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9767e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8301e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6762e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5755e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 9.1257e-04 - accuracy: 1.0000 - val_loss: 2.4954e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4057e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.9875e-04 - accuracy: 1.0000 - val_loss: 2.3126e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9930 - val_loss: 2.2748e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.1049e-04 - accuracy: 1.0000 - val_loss: 2.2627e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.5360e-04 - accuracy: 1.0000 - val_loss: 2.3018e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.2453e-04 - accuracy: 1.0000 - val_loss: 2.2917e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2538e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2340e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1649e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.5356e-04 - accuracy: 1.0000 - val_loss: 2.1114e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0611e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.9948e-04 - accuracy: 1.0000 - val_loss: 1.9979e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.9737e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 9.2806e-04 - accuracy: 1.0000 - val_loss: 1.9220e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 0s 4ms/step - loss: 9.8342e-04 - accuracy: 1.0000 - val_loss: 1.8823e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8540e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 7.7725e-04 - accuracy: 1.0000 - val_loss: 1.8220e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7763e-04 - val_accuracy: 1.0000\n",
      "Train on 142 samples, validate on 26 samples\n",
      "Epoch 1/38\n",
      "142/142 [==============================] - 6s 46ms/step - loss: 0.7301 - accuracy: 0.5000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 2/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.7606 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 3/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9437 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 4/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 5/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 6/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 7/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9930 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 8.2706e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 6.4756e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.4084e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.4957e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.0576e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.3996e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0332e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 2.8287e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6239e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.4984e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.3656e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2645e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1814e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 9.2938e-04 - accuracy: 1.0000 - val_loss: 2.0762e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/38\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 8.6637e-04 - accuracy: 1.0000 - val_loss: 1.9820e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 7.3951e-04 - accuracy: 1.0000 - val_loss: 1.9048e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 6.8062e-04 - accuracy: 1.0000 - val_loss: 1.8079e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/38\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.7041e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/38\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 8.5872e-04 - accuracy: 1.0000 - val_loss: 1.6201e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/38\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 5.3417e-04 - accuracy: 1.0000 - val_loss: 1.5753e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/38\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 5.9875e-04 - accuracy: 1.0000 - val_loss: 1.4801e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 5.3101e-04 - accuracy: 1.0000 - val_loss: 1.3893e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3408e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/38\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3043e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9930 - val_loss: 1.2468e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.1173e-04 - accuracy: 1.0000 - val_loss: 1.2197e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2003e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.7278e-04 - accuracy: 1.0000 - val_loss: 1.1636e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.8546e-04 - accuracy: 1.0000 - val_loss: 1.1291e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 3.3795e-04 - accuracy: 1.0000 - val_loss: 1.1050e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/38\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 4.6021e-04 - accuracy: 1.0000 - val_loss: 1.0951e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gs = pd.read_csv('LSTM_4_week_2.csv')\n",
    "gs.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "gd = gs[cols_to_use]\n",
    "Xtrain,Xtest,ytrain1,ytest1 = make_lstm(gd)\n",
    "an,y_model,y_answer = lstm_model(Xtrain,Xtest,ytrain1,ytest1)\n",
    "\n",
    "c_4w = mean_confidence_interval(an)\n",
    "cm = confusion_matrix(y_answer,y_model)\n",
    "ppv_4w = round(float(cm[0][0])/(cm[0][0]+cm[0][1]),2)\n",
    "npv_4w = round(float(cm[1][1])/(cm[1][0]+cm[1][1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------------------------------------+------+------+\n",
      "| Parameter |                             AUC-ROC                             | PPV  | NPV  |\n",
      "+-----------+-----------------------------------------------------------------+------+------+\n",
      "|   1 Hour  | (0.7824561403508772, -0.005179942726199371, 1.5700922234279537) | 0.86 | 0.6  |\n",
      "|   6 Hour  |   (0.7977725409836065, 0.6506357316279141, 0.9449093503392989)  | 0.7  | 0.69 |\n",
      "|  12 Hour  |   (0.7990888650244983, 0.7055292031701859, 0.8926485268788107)  | 0.85 | 0.5  |\n",
      "|  48 Hour  |   (0.8167186495187854, 0.6715589891132727, 0.961878309924298)   | 0.92 | 0.4  |\n",
      "|   1 Week  |   (0.8329340892986358, 0.7401633713291447, 0.9257048072681269)  | 0.9  | 0.26 |\n",
      "|   2 Week  |   (0.8102119976814529, 0.7631923096766999, 0.8572316856862059)  | 0.89 | 0.44 |\n",
      "|   3 Week  |  (0.7561325674434534, 0.26989195250226966, 1.2423731823846371)  | 0.81 | 0.44 |\n",
      "|   4 Week  |   (0.7297904929777654, 0.5806701355909867, 0.8789108503645442)  | 0.77 | 0.56 |\n",
      "+-----------+-----------------------------------------------------------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "l = [[\"1 Hour\" ,c_a, ppv_1,npv_1],[\"6 Hour\" ,c_6, ppv_6,npv_6],[\"12 Hour\" ,c_12, ppv_12,npv_12],[\"48 Hour\" ,c_48, ppv_48,npv_48],[\"1 Week\" ,c_1w, ppv_1w,npv_1w],[\"2 Week\" ,c_2w, ppv_2w,npv_3w],[\"3 Week\" ,c_3w, ppv_3w,npv_3w],[\"4 Week\" ,c_4w, ppv_4w,npv_4w]]\n",
    "\n",
    "table = PrettyTable(['Parameter', 'AUC-ROC', 'PPV','NPV'])\n",
    "\n",
    "for rec in l:\n",
    "    table.add_row(rec)\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
